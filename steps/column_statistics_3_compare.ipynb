{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Statistics Analysis - Step 3: Compare PCDS and AWS Results\n",
    "\n",
    "This notebook compares the column statistics collected from PCDS (step 1) and AWS (step 2).\n",
    "It generates Excel reports, CSV summaries, and JSON results showing any differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import re\nimport os\nimport csv\nimport json\nimport pickle\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport time\n\nfrom upath import UPath\nfrom loguru import logger\nfrom tqdm import tqdm\nfrom typing import Literal\nfrom dataclasses import dataclass, field, fields\nimport xlwings as xw\nfrom xlwings.constants import VAlign, HAlign\nfrom PIL import ImageColor\n\nwarnings.filterwarnings('ignore', message=r'pandas only supports SQLAlchemy connectable .*', category=UserWarning)\n\n# Note: This notebook uses Parquet format for cross-platform compatibility\n# Install pyarrow if needed: pip install pyarrow or conda install -c conda-forge pyarrow\nimport pyarrow\n\nget_rgb = ImageColor.getrgb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Constants and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Constants ---\n",
    "SEP = '; '\n",
    "AWS_DT_FORMAT = '%Y-%m-%d'\n",
    "TODAY = dt.datetime.now()\n",
    "WIDTH = 80\n",
    "\n",
    "TPartition = Literal['whole', 'year', 'year_month', 'empty', 'year_week', 'week', 'snapshot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Core Data Types and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Context manager for timing code execution\"\"\"\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return time.perf_counter() - self.start\n",
    "    \n",
    "    def pause(self):\n",
    "        \"\"\"Return elapsed time and reset timer\"\"\"\n",
    "        elapsed = self.time\n",
    "        self.start = time.perf_counter()\n",
    "        return elapsed\n",
    "\n",
    "    @staticmethod\n",
    "    def to_str(value):\n",
    "        \"\"\"Convert seconds to human-readable format\"\"\"\n",
    "        minutes, seconds = divmod(value, 60)\n",
    "        hours, minutes = divmod(minutes, 60)\n",
    "        return f'{hours} hours {minutes} minutes {seconds:.0f} seconds'\n",
    "\n",
    "@dataclass\n",
    "class MetaOut:\n",
    "    \"\"\"Metadata output structure\"\"\"\n",
    "    col2COL: dict\n",
    "    col2type: dict\n",
    "    infostr: str\n",
    "    rowvar: str\n",
    "    rowexclude: list\n",
    "    rowtype: str\n",
    "    nrows: int\n",
    "    where: str\n",
    "\n",
    "@dataclass(init=False)\n",
    "class MetaJSON:\n",
    "    \"\"\"Container for metadata from previous meta analysis step\"\"\"\n",
    "    pcds: MetaOut\n",
    "    aws: MetaOut\n",
    "    last_modified: str\n",
    "    partition: TPartition = 'whole'\n",
    "    tokenised_cols: list = field(default_factory=list)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        field_names = [f.name for f in fields(self)]\n",
    "        for k, v in kwargs.items():\n",
    "            if k in field_names:\n",
    "                setattr(self, k, v)\n",
    "        \n",
    "        def col2col(a_str, b_str, sep=SEP):\n",
    "            return {k: v for k, v in zip(a_str.split(sep), b_str.split(sep))}\n",
    "        \n",
    "        for key, other in [('pcds', 'aws'), ('aws', 'pcds')]:\n",
    "            out = MetaOut(\n",
    "                rowvar=kwargs['%s_dt' % key],\n",
    "                infostr=kwargs['%s_tbl' % key],\n",
    "                where=kwargs['%s_where' % key],\n",
    "                nrows=kwargs['%s_nrows' % key],\n",
    "                col2COL=col2col(kwargs['%s_cols' % key], kwargs['%s_cols' % other]),\n",
    "                col2type=col2col(kwargs['%s_cols' % key], kwargs['%s_types' % key]),\n",
    "                rowtype=kwargs['%s_dt_type' % key],\n",
    "                rowexclude=kwargs['%s_exclude' % key]\n",
    "            )\n",
    "            setattr(self, key, out)\n",
    "\n",
    "@dataclass\n",
    "class CSMeta:\n",
    "    \"\"\"Metadata for column statistics comparison\"\"\"\n",
    "    pcds_table: str\n",
    "    aws_table: str\n",
    "    partition: TPartition\n",
    "    vintage: str\n",
    "    pcds_time: int\n",
    "    aws_time: int\n",
    "\n",
    "    def todict(self):\n",
    "        return {f.name: getattr(self, f.name) for f in fields(self)}\n",
    "\n",
    "@dataclass\n",
    "class CSResult:\n",
    "    \"\"\"Results from column statistics comparison\"\"\"\n",
    "    pcds_stats: pd.DataFrame\n",
    "    aws_stats: pd.DataFrame\n",
    "    miss_columns: set\n",
    "    miss_details: dict\n",
    "    meta_data: CSMeta\n",
    "\n",
    "@dataclass\n",
    "class SQLRecord:\n",
    "    \"\"\"Record tracking for SQL analysis\"\"\"\n",
    "    name: str\n",
    "    unmatched: set = field(default_factory=set)\n",
    "    nrow: int = 0\n",
    "    ncol: int = 0\n",
    "    pcds_time: int = 0\n",
    "    aws_time: int = 0\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            old_v = getattr(self, k)\n",
    "            if k in ('unmatched',):\n",
    "                self.unmatched |= v\n",
    "            elif k in ('nrow', 'pcds_time', 'aws_time'):\n",
    "                setattr(self, k, old_v + v)\n",
    "            else:\n",
    "                setattr(self, k, v)\n",
    "\n",
    "    def toJSON(self):\n",
    "        return {\n",
    "            'Column Stats UnMatch': 'Yes' if len(self.unmatched) > 0 else 'No',\n",
    "            'Stats UnMatch Details': SEP.join(self.unmatched),\n",
    "            'Compared Dataset Shape': f'Row({self.nrow}) : Col({self.ncol})',\n",
    "            'Execution Time': 'PCDS({}) : AWS({})'.format(Timer.to_str(self.pcds_time), Timer.to_str(self.aws_time))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def start_run():\n    logger.info('\\n\\n' + '=' * WIDTH)\n\ndef end_run():\n    logger.info('\\n\\n' + '=' * WIDTH)\n\nclass IO:\n    \"\"\"File I/O utilities - uses Parquet/JSON for cross-platform compatibility\"\"\"\n\n    @staticmethod\n    def write_dataframe(file, df):\n        \"\"\"Save DataFrame in portable Parquet format\"\"\"\n        file = UPath(file)\n        df.to_parquet(file, index=True, engine='pyarrow', compression='snappy')\n\n    @staticmethod\n    def read_dataframe(file):\n        \"\"\"Load DataFrame from Parquet format\"\"\"\n        file = UPath(file)\n        return pd.read_parquet(file, engine='pyarrow')\n\n    @staticmethod\n    def write_json(file, data, cls=None):\n        \"\"\"Save to JSON with proper serialization\"\"\"\n        import numpy as np\n        import pandas as pd\n        import datetime as dt\n\n        def convert(obj):\n            if isinstance(obj, (np.integer, np.floating)):\n                return obj.item()\n            elif isinstance(obj, np.ndarray):\n                return obj.tolist()\n            elif pd.isna(obj):\n                return None\n            elif isinstance(obj, (dt.datetime, dt.date)):\n                return obj.isoformat()\n            elif isinstance(obj, set):\n                return list(obj)\n            raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n\n        with open(file, 'w') as f:\n            json.dump(data, f, indent=2, default=convert, cls=cls)\n\n    @staticmethod\n    def read_json(file):\n        \"\"\"Load from JSON\"\"\"\n        with open(file, 'r') as f:\n            return json.load(f)\n\n    @staticmethod\n    def write_pickle(file, data):\n        \"\"\"Deprecated: Use write_dataframe or write_json instead\"\"\"\n        with open(file, 'wb') as f:\n            pickle.dump(data, f)\n\n    @staticmethod\n    def read_pickle(file):\n        \"\"\"Deprecated: Use read_dataframe or read_json instead\"\"\"\n        with open(file, 'rb') as f:\n            return pickle.load(f)\n\n    @staticmethod\n    def read_meta_json(json_file):\n        \"\"\"Read metadata JSON and convert to MetaJSON objects\"\"\"\n        data = IO.read_json(json_file)\n        return {k: MetaJSON(**v) for k, v in data.items()}\n\n    @staticmethod\n    def delete_file(file):\n        if (filepath := UPath(file)).exists():\n            filepath.unlink()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Date Parsing Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_value(x, in_pcds=False, window=20):\n",
    "    \"\"\"Parse date value with special handling for PCDS format\"\"\"\n",
    "    if in_pcds and re.match(r'^\\d{2}-\\d{2}-\\d{4} \\d{2}:\\d{2}:\\d{2}$', str(x)):\n",
    "        date_part = pd.to_datetime(str(x).split(\" \")[0], format='%d-%m-%Y', dayfirst=True)\n",
    "        if date_part.year > TODAY.year + window:\n",
    "            date_part = date_part.replace(year=date_part.year - 100)\n",
    "        return date_part.strftime(AWS_DT_FORMAT)\n",
    "    try:\n",
    "        return pd.to_datetime(x).strftime(AWS_DT_FORMAT)\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        return str(x) if not pd.isna(x) else x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Column Comparator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnComparator:\n",
    "    \"\"\"Enhanced column comparison engine for PCDS and AWS data\"\"\"\n",
    "    \n",
    "    statistics = {\n",
    "        'col_type': 'Type',\n",
    "        'col_count': 'N_Total',\n",
    "        'col_distinct': 'N_Unique',\n",
    "        'col_missing': 'N_Missing',\n",
    "        'col_max': 'Max',\n",
    "        'col_min': 'Min',\n",
    "        'col_avg': 'Mean',\n",
    "        'col_std': 'Std',\n",
    "        'col_sum': 'Sum',\n",
    "        'col_sum_sq': 'Sum_Square',\n",
    "        'col_freq': 'Frequency'\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.comparison_results = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_value(row: pd.Series, column: str, is_pcds: bool = False):\n",
    "        \"\"\"Extract and parse value from statistics row\"\"\"\n",
    "        value = row.get(column, np.nan) or np.nan\n",
    "        is_date = bool(re.match(r'^date|time', str(row['col_type']), re.I))\n",
    "        \n",
    "        # Parse frequency distribution\n",
    "        if column == 'col_freq' and isinstance(value, str):\n",
    "            value = sorted([\n",
    "                m.groups() for s in value.split('; ')\n",
    "                if (m := re.search(r'([^(]*)\\((\\d+)\\)', s.strip()))\n",
    "            ], key=lambda x: (-int(x[1]), parse_date_value(x[0], is_pcds)))\n",
    "        \n",
    "        # Try numeric conversion\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            try:\n",
    "                return int(value)\n",
    "            except (ValueError, TypeError):\n",
    "                return value\n",
    "\n",
    "    @staticmethod\n",
    "    def contains_datelike(dtype1, dtype2):\n",
    "        \"\"\"Check if either type is date/timestamp\"\"\"\n",
    "        return bool({str(dtype1).lower(), str(dtype2).lower()} & {'date', 'timestamp'})\n",
    "\n",
    "    def compare_statistics(\n",
    "        self,\n",
    "        pcds_stats: pd.DataFrame,\n",
    "        aws_stats: pd.DataFrame,\n",
    "        column_mapping: dict[str, str],\n",
    "        tokenised_cols: list\n",
    "    ) -> tuple[dict[str, any], pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Compare statistics between PCDS and AWS\"\"\"\n",
    "        mismatched_columns = set()\n",
    "        mismatched_details = {}\n",
    "        \n",
    "        # Align columns based on mapping\n",
    "        aligned_pcds = pcds_stats.copy()\n",
    "        aligned_aws = aws_stats.copy()\n",
    "        \n",
    "        # Remove tokenised columns and rename\n",
    "        aligned_pcds = (\n",
    "            aligned_pcds\n",
    "            .drop(index=tokenised_cols, errors='ignore')\n",
    "            .rename(index=column_mapping)\n",
    "        )\n",
    "        \n",
    "        # Compare common columns\n",
    "        common_columns = set(aligned_pcds.index) & set(aligned_aws.index)\n",
    "        for column in common_columns:\n",
    "            pcds_row = aligned_pcds.loc[column]\n",
    "            aws_row = aligned_aws.loc[column]\n",
    "            column_diffs = {}\n",
    "            has_mismatch = False\n",
    "            \n",
    "            for stat, name in self.statistics.items():\n",
    "                if stat in ('col_type',):\n",
    "                    continue\n",
    "                \n",
    "                # Skip date frequency comparison\n",
    "                if stat == 'col_freq' and self.contains_datelike(\n",
    "                    pcds_row['col_type'], aws_row['col_type']\n",
    "                ):\n",
    "                    continue\n",
    "                \n",
    "                pcds_val = self.get_value(pcds_row, stat, True)\n",
    "                aws_val = self.get_value(aws_row, stat)\n",
    "                \n",
    "                if self._values_different(pcds_val, aws_val):\n",
    "                    column_diffs[name] = {'pcds': pcds_val, 'aws': aws_val}\n",
    "                    has_mismatch = True\n",
    "            \n",
    "            if has_mismatch:\n",
    "                mismatched_columns.add(column)\n",
    "                mismatched_details[column] = column_diffs\n",
    "                logger.warning(f\"Mismatch found in column {column}: {column_diffs}\")\n",
    "        \n",
    "        # Format output\n",
    "        pcds_stats_formatted = (\n",
    "            pcds_stats.loc[list(column_mapping)]\n",
    "            [list(self.statistics)]\n",
    "            .rename(columns=self.statistics)\n",
    "        )\n",
    "        aws_stats_formatted = (\n",
    "            aws_stats.loc[[v for k, v in column_mapping.items()]]\n",
    "            [list(self.statistics)]\n",
    "            .rename(columns=self.statistics)\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'mismatched_columns': mismatched_columns,\n",
    "            'mismatched_details': mismatched_details,\n",
    "            'total_columns': len(common_columns),\n",
    "            'matched_columns': len(common_columns) - len(mismatched_columns),\n",
    "        }\n",
    "        return results, pcds_stats_formatted, aws_stats_formatted\n",
    "\n",
    "    @staticmethod\n",
    "    def _values_different(val1, val2) -> bool:\n",
    "        \"\"\"Check if two values are different with tolerance\"\"\"\n",
    "        # Handle list comparisons (frequency distributions)\n",
    "        if isinstance(val1, list):\n",
    "            if not isinstance(val2, list) or len(val1) != len(val2):\n",
    "                return True\n",
    "            flag = any(\n",
    "                ColumnComparator._values_different(x1, x2)\n",
    "                for t1, t2 in zip(val1, val2)\n",
    "                for x1, x2 in zip(t1, t2)\n",
    "            )\n",
    "            return flag\n",
    "        \n",
    "        # Handle NaN values\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return False\n",
    "        if val1 == 0 and pd.isna(val2):\n",
    "            return False\n",
    "        if pd.isna(val1) ^ pd.isna(val2):\n",
    "            return True\n",
    "        \n",
    "        # Try date comparison\n",
    "        try:\n",
    "            dat1 = parse_date_value(val1, in_pcds=True)\n",
    "            dat2 = parse_date_value(val2)\n",
    "            return dat1 != dat2\n",
    "        except (ValueError, TypeError):\n",
    "            # Try numeric comparison\n",
    "            try:\n",
    "                num1, num2 = float(val1), float(val2)\n",
    "                return not np.isclose(num1, num2, atol=1e-6, rtol=1e-6)\n",
    "            except (ValueError, TypeError):\n",
    "                # Fall back to string comparison\n",
    "                return str(val1) != str(val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Excel Report Generation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XS:\n",
    "    \"\"\"Excel styling helper\"\"\"\n",
    "    \n",
    "    def __init__(self, ws: xw.Range):\n",
    "        self.ws = ws\n",
    "\n",
    "    def get_color(self, color):\n",
    "        if isinstance(color, str):\n",
    "            return get_rgb(color)\n",
    "        return color\n",
    "\n",
    "    def apply_styles(self, pos='A1', value='', font={}, align='left', color='', border={}):\n",
    "        \"\"\"Apply styles to a cell\"\"\"\n",
    "        cell = self.make_cell(pos)\n",
    "        if value:\n",
    "            cell.value = value\n",
    "        if font:\n",
    "            if 'family' in font:\n",
    "                cell.font.name = font['family']\n",
    "            if 'size' in font:\n",
    "                cell.font.size = font['size']\n",
    "            if 'color' in font:\n",
    "                cell.font.color = self.get_color(font['color'])\n",
    "            if 'bold' in font:\n",
    "                cell.font.bold = font['bold']\n",
    "        if color:\n",
    "            cell.color = self.get_color(color)\n",
    "        if 'style' in border:\n",
    "            cell.api.Borders.LineStyle = border['style']\n",
    "        if align == 'right':\n",
    "            cell.api.HorizontalAlignment = HAlign.xlHAlignRight\n",
    "        elif align == 'left':\n",
    "            cell.api.HorizontalAlignment = HAlign.xlHAlignLeft\n",
    "        elif align == 'center':\n",
    "            cell.api.HorizontalAlignment = HAlign.xlHAlignCenter\n",
    "\n",
    "    def make_cell(self, pos='A1', value=None):\n",
    "        cell = self.ws.range(pos)\n",
    "        if value is not None:\n",
    "            cell.value = value\n",
    "        return cell\n",
    "\n",
    "    def write_dataframe(self, df: pd.DataFrame, pos='A1', header=True, index=False):\n",
    "        cell = self.make_cell(pos)\n",
    "        cell.options(index=index, header=header).value = df\n",
    "        return cell\n",
    "\n",
    "class ExcelReporter:\n",
    "    \"\"\"Excel reporter for column comparison results\"\"\"\n",
    "    \n",
    "    def __init__(self, workbook_path: str):\n",
    "        self.workbook_path = UPath(workbook_path)\n",
    "        self.app = None\n",
    "        self.wb = None\n",
    "        self.ns = -1\n",
    "        self.cx, self.cy = None, None\n",
    "\n",
    "    def __enter__(self):\n",
    "        try:\n",
    "            self.workbook_path.unlink(True)\n",
    "        except PermissionError:\n",
    "            xw.Book(self.workbook_path).close()\n",
    "        self.app = xw.App(visible=True, add_book=False)\n",
    "        self.wb = self.app.books.add()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.wb:\n",
    "            self.wb.save(str(self.workbook_path))\n",
    "\n",
    "    def create_comparison_report(self, comparison_results: dict[str, dict[str, CSResult]]):\n",
    "        \"\"\"Create Excel report with comparison results\"\"\"\n",
    "        self._create_summary_sheet(comparison_results)\n",
    "        for dataset_name, dataset_data in comparison_results.items():\n",
    "            self._create_dataset_sheet(dataset_name, dataset_data)\n",
    "\n",
    "    def _create_summary_sheet(self, comparison_results):\n",
    "        \"\"\"Create summary sheet with overview\"\"\"\n",
    "        ws = self.wb.sheets[0]\n",
    "        ws.name = 'SUMMARY'\n",
    "        ws.range('A1').value = 'Column Statistics Comparison'\n",
    "        ws.range('A1').font.bold = True\n",
    "        ws.range('A1').font.size = 14\n",
    "        headers = ['Dataset', 'Vintage', 'Total Columns', 'Matched Columns', 'Mismatched Columns', 'Match Rate %']\n",
    "        ws.range('A3').value = headers\n",
    "        ws.range('A3:F3').font.bold = True\n",
    "        ws.range('A3:F3').color = (200, 200, 200)\n",
    "        \n",
    "        row = 4\n",
    "        for dataset_name, dataset_data in comparison_results.items():\n",
    "            for vintage, data in dataset_data.items():\n",
    "                pcds_stats = data.pcds_stats\n",
    "                matched = (total_cols := len(pcds_stats)) - (mismatched := len(data.miss_columns))\n",
    "                match_rate = (matched / total_cols * 100) if total_cols > 0 else 0\n",
    "                ws.range(f'A{row}').value = [dataset_name, vintage, total_cols, matched, mismatched, f'{match_rate:.1f}%']\n",
    "                if match_rate >= 95:\n",
    "                    ws.range(f'A{row}:F{row}').color = (200, 255, 200)\n",
    "                else:\n",
    "                    ws.range(f'A{row}:F{row}').color = (255, 200, 200)\n",
    "                row += 1\n",
    "        ws.autofit()\n",
    "        self.ns += 1\n",
    "\n",
    "    def _create_dataset_sheet(self, name: str, result_d: dict[str, CSResult]):\n",
    "        \"\"\"Create detailed sheet for a specific dataset\"\"\"\n",
    "        wb = self.wb\n",
    "        # Truncate name to 31 characters (Excel limit)\n",
    "        sheet_name = name.upper()[:31]\n",
    "        try:\n",
    "            ws = wb.sheets.add(sheet_name, after=wb.sheets[self.ns])\n",
    "        except ValueError:\n",
    "            ws = wb.sheets[sheet_name]\n",
    "        finally:\n",
    "            ws.clear()\n",
    "        xs = XS(ws)\n",
    "        \n",
    "        row = 1\n",
    "        for vintage, data in result_d.items():\n",
    "            # Write vintage header\n",
    "            xs.make_cell(pos=f'A{row}', value='Vintage: ')\n",
    "            xs.apply_styles(pos=f'B{row}', value=vintage, align='right')\n",
    "            ws.range(f'B{row}:D{row}').merge()\n",
    "            xs.apply_styles(f'A{row}:D{row}', font={'bold': True}, color=(190, 190, 190))\n",
    "            row += 2\n",
    "            \n",
    "            # Write PCDS statistics\n",
    "            pcds_tbl = data.meta_data.pcds_table.split('.')[-1]\n",
    "            xs.make_cell(pos=f'A{row}', value='PCDS: ')\n",
    "            xs.apply_styles(pos=f'B{row}', value=pcds_tbl, align='right')\n",
    "            ws.range(f'B{row}:D{row}').merge()\n",
    "            xs.apply_styles(f'A{row}:D{row}', font={'bold': True}, color=(240, 240, 240))\n",
    "            row += 1\n",
    "            \n",
    "            # Reorder columns to show mismatches first\n",
    "            aws_view = data.aws_stats.T.map(self._format_cell_value)\n",
    "            indices = [i for i, x in enumerate(aws_view.columns) if x in data.miss_columns]\n",
    "            the_rest = [i for i in range(len(aws_view.columns)) if i not in indices]\n",
    "            aws_view = aws_view[aws_view.columns[indices + the_rest]]\n",
    "            pcds_view = data.pcds_stats.T.map(self._format_cell_value)\n",
    "            pcds_view = pcds_view[pcds_view.columns[indices + the_rest]]\n",
    "            \n",
    "            self.cx, self.cy = 2, row + 1\n",
    "            xs.write_dataframe(pcds_view, f'B{row}', index=True)\n",
    "            \n",
    "            # Write AWS statistics\n",
    "            row += len(pcds_view) + 2\n",
    "            xs.make_cell(pos=f'A{row}', value='AWS: ')\n",
    "            aws_tbl = data.meta_data.aws_table.lower()\n",
    "            xs.apply_styles(pos=f'B{row}', value=aws_tbl, align='right')\n",
    "            ws.range(f'B{row}:D{row}').merge()\n",
    "            xs.apply_styles(f'A{row}:D{row}', font={'bold': True}, color=(240, 240, 240))\n",
    "            row += 1\n",
    "            xs.write_dataframe(aws_view, f'B{row}', index=True)\n",
    "            row += len(aws_view) + 3\n",
    "            \n",
    "            self._highlight_differences(ws, nx=len(indices), ny=len(pcds_view) - 1)\n",
    "            row += 2\n",
    "        ws.autofit()\n",
    "        self.ns += 1\n",
    "\n",
    "    def _highlight_differences(self, ws: xw.Sheet, nx: int, ny: int):\n",
    "        \"\"\"Highlight differences between PCDS and AWS\"\"\"\n",
    "        ix, iy = self.cx, self.cy\n",
    "        for i in range(iy, iy + ny):\n",
    "            for j in range(ix, ix + nx):\n",
    "                pcds, aws = ws[i, j], ws[i + ny + 4, j]\n",
    "                pcds.number_format = '0.00'\n",
    "                aws.number_format = '0.00'\n",
    "                if pcds.value == aws.value:\n",
    "                    pcds.font.color = get_rgb('green')\n",
    "                    aws.font.color = get_rgb('green')\n",
    "                else:\n",
    "                    pcds.font.color = get_rgb('red')\n",
    "                    aws.font.color = get_rgb('red')\n",
    "\n",
    "    def _format_cell_value(self, value) -> str:\n",
    "        \"\"\"Format cell value for display\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return ''\n",
    "        elif isinstance(value, (int, float)):\n",
    "            if isinstance(value, float) and value.is_integer():\n",
    "                return str(int(value))\n",
    "            return str(value)\n",
    "        else:\n",
    "            str_val = str(value)\n",
    "            return str_val[:50] + '...' if len(str_val) > 50 else str_val\n",
    "\n",
    "def create_comparison_report(comparison_results: dict[str, dict[str, CSResult]], output_path: UPath):\n",
    "    \"\"\"Create comparison report from results dictionary\"\"\"\n",
    "    with ExcelReporter(output_path) as reporter:\n",
    "        reporter.create_comparison_report(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Main Execution - Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def main_compare():\n    \"\"\"Main execution function for column statistics comparison\"\"\"\n\n    # Configuration - adjust these paths as needed\n    meta_json_path = 'path/to/meta_analysis_output.json'  # From meta_analysis step\n    meta_csv_path = 'path/to/meta_analysis.csv'\n    pcds_summary_path = 'output/column_stats_pcds/pcds_summary.json'  # From step 1\n    aws_summary_path = 'output/column_stats_aws/aws_summary.json'  # From step 2\n\n    output_folder = UPath('output/column_stats_compare')\n    output_folder.mkdir(exist_ok=True, parents=True)\n\n    csv_output = output_folder / 'comparison_summary.csv'\n    json_output = output_folder / 'comparison_results.json'\n    excel_output = output_folder / 'comparison_report.xlsx'\n\n    start_run()\n\n    # Load metadata from meta_analysis step\n    meta_json = IO.read_meta_json(meta_json_path)\n    meta_csv = pd.read_csv(meta_csv_path)\n\n    # Load summary files from steps 1 and 2\n    logger.info(\"Loading PCDS summary from step 1...\")\n    if not UPath(pcds_summary_path).exists():\n        logger.error(f\"PCDS summary not found: {pcds_summary_path}\")\n        logger.error(\"Please run Step 1 (column_statistics_1_pcds.ipynb) first!\")\n        return\n\n    pcds_summary = IO.read_json(pcds_summary_path)\n\n    logger.info(\"Loading AWS summary from step 2...\")\n    if not UPath(aws_summary_path).exists():\n        logger.error(f\"AWS summary not found: {aws_summary_path}\")\n        logger.error(\"Please run Step 2 (column_statistics_2_aws.ipynb) first!\")\n        return\n\n    aws_summary = IO.read_json(aws_summary_path)\n\n    CC = ColumnComparator()\n    ALL_RESULT = {}\n    HAS_HEADER = False\n\n    # CSV columns for summary\n    csv_columns = [\n        'Dataset',\n        'Vintage',\n        'Column Stats UnMatch',\n        'Stats UnMatch Details',\n        'Compared Dataset Shape',\n        'Execution Time'\n    ]\n\n    for i, row in tqdm(meta_csv.iterrows(), desc='Comparing datasets...', total=len(meta_csv)):\n        name = row.get('PCDS Table Details with DB Name')\n        logger.info(f\"Processing dataset: {name}\")\n\n        # Load metadata for this table\n        meta_info = meta_json.get(name)\n        if not meta_info:\n            logger.warning(f\"No metadata found for {name}\")\n            continue\n\n        # Check if we have results for this dataset\n        if name not in pcds_summary or name not in aws_summary:\n            logger.warning(f\"Missing results for {name}\")\n            continue\n\n        meta_pcds = meta_info.pcds\n        partition = meta_info.partition\n\n        if partition == 'empty':\n            continue\n\n        DATA_RESULT = {}\n        record = SQLRecord(name=name)\n\n        # Get vintages from summaries\n        pcds_vintages = pcds_summary[name]\n        aws_vintages = aws_summary[name]\n\n        # Process each vintage\n        common_vintages = set(pcds_vintages.keys()) & set(aws_vintages.keys())\n\n        for vintage in common_vintages:\n            logger.info(f\"Comparing vintage: {vintage}\")\n\n            # Load statistics from parquet files\n            pcds_info = pcds_vintages[vintage]\n            aws_info = aws_vintages[vintage]\n\n            pcds_stats_file = UPath(pcds_info['stats_file'])\n            aws_stats_file = UPath(aws_info['stats_file'])\n\n            if not pcds_stats_file.exists() or not aws_stats_file.exists():\n                logger.warning(f\"Missing stats files for {name}/{vintage}\")\n                continue\n\n            pcds_stats = IO.read_dataframe(pcds_stats_file)\n            aws_stats = IO.read_dataframe(aws_stats_file)\n\n            # Get timing information\n            pcds_time = pcds_info['meta_data'].get('pcds_time', 0)\n            aws_time = aws_info['meta_data'].get('aws_time', 0)\n\n            # Compare statistics\n            comparison_result, pcds_stats_formatted, aws_stats_formatted = CC.compare_statistics(\n                pcds_stats, aws_stats, meta_pcds.col2COL, meta_info.tokenised_cols\n            )\n\n            # Store results\n            DATA_RESULT[vintage] = CSResult(\n                pcds_stats=pcds_stats_formatted,\n                aws_stats=aws_stats_formatted,\n                miss_columns=comparison_result['mismatched_columns'],\n                miss_details=comparison_result['mismatched_details'],\n                meta_data=CSMeta(\n                    pcds_table=meta_pcds.infostr,\n                    aws_table=meta_info.aws.infostr,\n                    partition=partition,\n                    vintage=vintage,\n                    pcds_time=pcds_time,\n                    aws_time=aws_time,\n                )\n            )\n\n            # Update record\n            record.update(\n                unmatched=comparison_result['mismatched_columns'],\n                nrow=int(pcds_stats_formatted['N_Total'].max()),\n                ncol=comparison_result['total_columns'],\n                pcds_time=pcds_time,\n                aws_time=aws_time\n            )\n\n            logger.info(\n                f\"Vintage {vintage}: {comparison_result['matched_columns']}/{comparison_result['total_columns']} \"\n                f\"columns matched\"\n            )\n\n        ALL_RESULT[name] = DATA_RESULT\n\n        # Write results to CSV\n        with open(csv_output, 'a+', newline='') as fp:\n            writer = csv.DictWriter(fp, fieldnames=csv_columns)\n            if not HAS_HEADER:\n                writer.writeheader()\n                HAS_HEADER = True\n\n            for vintage in DATA_RESULT.keys():\n                csv_row = {\n                    'Dataset': name,\n                    'Vintage': vintage,\n                    **record.toJSON()\n                }\n                writer.writerow(csv_row)\n\n    # Save results to JSON\n    logger.info(f\"Saving comparison results to {json_output}\")\n    IO.write_json(json_output, {\n        dataset: {\n            vintage: {\n                'mismatched_columns': list(data.miss_columns),\n                'mismatched_details': data.miss_details,\n                'metadata': data.meta_data.todict()\n            } for vintage, data in vintages.items()\n        } for dataset, vintages in ALL_RESULT.items()\n    })\n\n    # Create Excel report\n    logger.info(f\"Creating Excel report at {excel_output}\")\n    create_comparison_report(ALL_RESULT, excel_output)\n    logger.info(f\"Excel report created: {excel_output}\")\n\n    # Summary statistics\n    total_datasets = len(ALL_RESULT)\n    total_comparisons = sum(len(vintages) for vintages in ALL_RESULT.values())\n    datasets_with_issues = sum(\n        1 for vintages in ALL_RESULT.values()\n        if any(len(data.miss_columns) > 0 for data in vintages.values())\n    )\n\n    logger.info(f\"\\n{'='*80}\")\n    logger.info(\"Comparison Summary:\")\n    logger.info(f\"  Total datasets compared: {total_datasets}\")\n    logger.info(f\"  Total comparisons (including vintages): {total_comparisons}\")\n    logger.info(f\"  Datasets with mismatches: {datasets_with_issues}\")\n    logger.info(f\"  CSV summary: {csv_output}\")\n    logger.info(f\"  JSON results: {json_output}\")\n    logger.info(f\"  Excel report: {excel_output}\")\n    logger.info(f\"{'='*80}\\n\")\n\n    end_run()\n    return ALL_RESULT\n\nif __name__ == '__main__':\n    results = main_compare()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Comparison\n",
    "\n",
    "Uncomment the cell below to run the comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = main_compare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}