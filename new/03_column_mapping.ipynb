{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Column Mapping and Crosswalk\n",
    "\n",
    "This notebook:\n",
    "- Loads configuration from Step 2\n",
    "- Loads column crosswalk mappings from XLSX\n",
    "- Queries actual PCDS and AWS column metadata\n",
    "- Identifies comparable columns (PCDS ↔ AWS)\n",
    "- Updates JSON with comparable column mappings\n",
    "\n",
    "**Input**: `data/config.json`, crosswalk XLSX  \n",
    "**Output**: Updated `data/config.json` with column_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Step 3: Column Mapping and Crosswalk\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_JSON = \"data/config.json\"\n",
    "\n",
    "with open(CONFIG_JSON, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"Loaded configuration: {config['run_name']}\")\n",
    "print(f\"Total tables: {config['metadata']['total_tables']}\")\n",
    "print(f\"Step 2 completed: {config['status']['step2_completed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load Crosswalk Mapping (Optional)\n",
    "\n",
    "If you have a predefined crosswalk XLSX, load it here. Otherwise, we'll infer mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosswalk file (optional)\n",
    "CROSSWALK_XLSX = \"../files/inputs/crosswalk.xlsx\"  # Update path as needed\n",
    "\n",
    "try:\n",
    "    df_crosswalk = pd.read_excel(CROSSWALK_XLSX)\n",
    "    print(f\"Loaded crosswalk with {len(df_crosswalk)} mappings\")\n",
    "    print(f\"Columns: {list(df_crosswalk.columns)}\")\n",
    "    display(df_crosswalk.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Crosswalk file not found: {CROSSWALK_XLSX}\")\n",
    "    print(\"Will infer column mappings from schema metadata\")\n",
    "    df_crosswalk = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Define Column Metadata Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcds_columns(table_name):\n",
    "    \"\"\"\n",
    "    Query PCDS (Oracle) for column metadata\n",
    "    \n",
    "    Args:\n",
    "        table_name: PCDS table name\n",
    "    \n",
    "    Returns:\n",
    "        dict: {column_name: {'data_type': str, 'nullable': bool, ...}}\n",
    "    \"\"\"\n",
    "    # TODO: Implement actual Oracle query\n",
    "    # Example SQL:\n",
    "    # SELECT column_name, data_type, nullable\n",
    "    # FROM all_tab_columns\n",
    "    # WHERE table_name = '{table_name}'\n",
    "    # ORDER BY column_id\n",
    "    \n",
    "    print(f\"  [PCDS] Querying schema for {table_name}...\")\n",
    "    \n",
    "    # Placeholder - replace with actual query\n",
    "    return {\n",
    "        'CUSTOMER_ID': {'data_type': 'NUMBER', 'nullable': False},\n",
    "        'CUSTOMER_NAME': {'data_type': 'VARCHAR2', 'nullable': True},\n",
    "        'CREATE_DT': {'data_type': 'DATE', 'nullable': True},\n",
    "    }\n",
    "\n",
    "\n",
    "def get_aws_columns(table_name):\n",
    "    \"\"\"\n",
    "    Query AWS Athena for column metadata\n",
    "    \n",
    "    Args:\n",
    "        table_name: AWS table name\n",
    "    \n",
    "    Returns:\n",
    "        dict: {column_name: {'data_type': str, 'nullable': bool, ...}}\n",
    "    \"\"\"\n",
    "    # TODO: Implement actual Athena query\n",
    "    # Example SQL:\n",
    "    # DESCRIBE {table_name}\n",
    "    # or\n",
    "    # SELECT * FROM information_schema.columns\n",
    "    # WHERE table_name = '{table_name}'\n",
    "    \n",
    "    print(f\"  [AWS]  Querying schema for {table_name}...\")\n",
    "    \n",
    "    # Placeholder - replace with actual query\n",
    "    return {\n",
    "        'customer_id': {'data_type': 'bigint', 'nullable': False},\n",
    "        'customer_name': {'data_type': 'string', 'nullable': True},\n",
    "        'create_dt': {'data_type': 'timestamp', 'nullable': True},\n",
    "    }\n",
    "\n",
    "\n",
    "def map_column_types(pcds_type, aws_type):\n",
    "    \"\"\"\n",
    "    Check if PCDS and AWS column types are compatible\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_compatible, compatibility_status)\n",
    "    \"\"\"\n",
    "    # Type mapping rules\n",
    "    type_map = {\n",
    "        'NUMBER': ['bigint', 'int', 'double', 'decimal'],\n",
    "        'VARCHAR2': ['string', 'varchar'],\n",
    "        'DATE': ['timestamp', 'date'],\n",
    "        'TIMESTAMP': ['timestamp'],\n",
    "    }\n",
    "    \n",
    "    pcds_upper = pcds_type.upper()\n",
    "    aws_lower = aws_type.lower()\n",
    "    \n",
    "    for pcds_key, aws_values in type_map.items():\n",
    "        if pcds_upper.startswith(pcds_key):\n",
    "            if any(aws_lower.startswith(av) for av in aws_values):\n",
    "                return True, 'compatible'\n",
    "            else:\n",
    "                return False, 'type_mismatch'\n",
    "    \n",
    "    return False, 'unknown_type'\n",
    "\n",
    "\n",
    "print(\"Column metadata query functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Build Column Mappings for Each Table Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mappings = []\n",
    "\n",
    "for idx, table_pair in enumerate(config['table_pairs'], 1):\n",
    "    print(f\"\\n[{idx}/{len(config['table_pairs'])}] Processing:\")\n",
    "    print(f\"  PCDS: {table_pair['pcds_tbl']}\")\n",
    "    print(f\"  AWS:  {table_pair['aws_tbl']}\")\n",
    "    \n",
    "    # Get column metadata\n",
    "    pcds_cols = get_pcds_columns(table_pair['pcds_tbl'])\n",
    "    aws_cols = get_aws_columns(table_pair['aws_tbl'])\n",
    "    \n",
    "    print(f\"  PCDS columns: {len(pcds_cols)}\")\n",
    "    print(f\"  AWS columns: {len(aws_cols)}\")\n",
    "    \n",
    "    # Build mapping\n",
    "    pcds_to_aws = {}\n",
    "    aws_to_pcds = {}\n",
    "    comparable_cols = []\n",
    "    pcds_only = []\n",
    "    aws_only = []\n",
    "    type_mismatches = []\n",
    "    \n",
    "    # Create lowercase mapping for AWS (case-insensitive matching)\n",
    "    aws_cols_lower = {k.lower(): (k, v) for k, v in aws_cols.items()}\n",
    "    \n",
    "    # Map PCDS columns to AWS\n",
    "    for pcds_col, pcds_meta in pcds_cols.items():\n",
    "        # Try exact match (case-insensitive)\n",
    "        aws_col_lower = pcds_col.lower()\n",
    "        \n",
    "        if aws_col_lower in aws_cols_lower:\n",
    "            aws_col, aws_meta = aws_cols_lower[aws_col_lower]\n",
    "            \n",
    "            # Check type compatibility\n",
    "            is_compatible, compat_status = map_column_types(\n",
    "                pcds_meta['data_type'], \n",
    "                aws_meta['data_type']\n",
    "            )\n",
    "            \n",
    "            pcds_to_aws[pcds_col] = aws_col\n",
    "            aws_to_pcds[aws_col] = pcds_col\n",
    "            \n",
    "            if is_compatible:\n",
    "                comparable_cols.append({\n",
    "                    'pcds_col': pcds_col,\n",
    "                    'aws_col': aws_col,\n",
    "                    'pcds_type': pcds_meta['data_type'],\n",
    "                    'aws_type': aws_meta['data_type'],\n",
    "                    'status': 'perfect_match'\n",
    "                })\n",
    "            else:\n",
    "                type_mismatches.append({\n",
    "                    'pcds_col': pcds_col,\n",
    "                    'aws_col': aws_col,\n",
    "                    'pcds_type': pcds_meta['data_type'],\n",
    "                    'aws_type': aws_meta['data_type'],\n",
    "                    'status': 'type_mismatch'\n",
    "                })\n",
    "        else:\n",
    "            pcds_only.append(pcds_col)\n",
    "    \n",
    "    # Find AWS-only columns\n",
    "    for aws_col in aws_cols.keys():\n",
    "        if aws_col not in aws_to_pcds:\n",
    "            aws_only.append(aws_col)\n",
    "    \n",
    "    # Store mapping result\n",
    "    mapping_result = {\n",
    "        'table_index': idx - 1,\n",
    "        'pcds_tbl': table_pair['pcds_tbl'],\n",
    "        'aws_tbl': table_pair['aws_tbl'],\n",
    "        'pcds_to_aws': pcds_to_aws,\n",
    "        'aws_to_pcds': aws_to_pcds,\n",
    "        'comparable_columns': comparable_cols,\n",
    "        'type_mismatches': type_mismatches,\n",
    "        'pcds_only': pcds_only,\n",
    "        'aws_only': aws_only,\n",
    "        'stats': {\n",
    "            'total_comparable': len(comparable_cols),\n",
    "            'type_mismatches': len(type_mismatches),\n",
    "            'pcds_only': len(pcds_only),\n",
    "            'aws_only': len(aws_only)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    column_mappings.append(mapping_result)\n",
    "    \n",
    "    print(f\"  ✓ Comparable: {len(comparable_cols)}\")\n",
    "    print(f\"  ⚠ Type mismatches: {len(type_mismatches)}\")\n",
    "    print(f\"  PCDS only: {len(pcds_only)}\")\n",
    "    print(f\"  AWS only: {len(aws_only)}\")\n",
    "\n",
    "print(f\"\\n✓ Column mapping complete for {len(column_mappings)} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Mapping Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_comparable = sum(m['stats']['total_comparable'] for m in column_mappings)\n",
    "total_mismatches = sum(m['stats']['type_mismatches'] for m in column_mappings)\n",
    "total_pcds_only = sum(m['stats']['pcds_only'] for m in column_mappings)\n",
    "total_aws_only = sum(m['stats']['aws_only'] for m in column_mappings)\n",
    "\n",
    "print(f\"Total comparable columns: {total_comparable}\")\n",
    "print(f\"Total type mismatches: {total_mismatches}\")\n",
    "print(f\"Total PCDS-only columns: {total_pcds_only}\")\n",
    "print(f\"Total AWS-only columns: {total_aws_only}\")\n",
    "\n",
    "# Show tables with type mismatches\n",
    "if total_mismatches > 0:\n",
    "    print(\"\\n⚠ Tables with type mismatches:\")\n",
    "    for m in column_mappings:\n",
    "        if m['stats']['type_mismatches'] > 0:\n",
    "            print(f\"  - {m['pcds_tbl']}: {m['stats']['type_mismatches']} mismatches\")\n",
    "            for tm in m['type_mismatches']:\n",
    "                print(f\"    • {tm['pcds_col']} ({tm['pcds_type']}) -> {tm['aws_col']} ({tm['aws_type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Update Configuration JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column mappings to config\n",
    "config['column_mappings'] = column_mappings\n",
    "config['status']['step3_completed'] = True\n",
    "config['status']['step3_completed_at'] = datetime.now().isoformat()\n",
    "\n",
    "# Save updated config\n",
    "with open(CONFIG_JSON, 'w') as f:\n",
    "    json.dump(config, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Configuration updated and saved to: {CONFIG_JSON}\")\n",
    "print(f\"\\n✓ Step 3 Complete - Ready for Step 4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
