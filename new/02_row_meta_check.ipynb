{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Row Meta Check\n",
    "\n",
    "This notebook:\n",
    "- Loads configuration from Step 1\n",
    "- Queries row counts for each partition/vintage\n",
    "- Compares PCDS vs AWS row counts\n",
    "- Updates JSON with results\n",
    "\n",
    "**Input**: `data/config.json`  \n",
    "**Output**: Updated `data/config.json` with row_meta results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Step 2: Row Meta Check\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_JSON = \"data/config.json\"\n",
    "\n",
    "with open(CONFIG_JSON, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"Loaded configuration: {config['run_name']}\")\n",
    "print(f\"Total tables: {config['metadata']['total_tables']}\")\n",
    "print(f\"Step 1 completed: {config['status']['step1_completed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define Row Count Query Functions\n",
    "\n",
    "These functions need to be implemented with actual database connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcds_row_count(table_name, date_col, vintage, partition_type, where_clause=None):\n",
    "    \"\"\"\n",
    "    Query PCDS (Oracle) for row count\n",
    "    \n",
    "    Args:\n",
    "        table_name: PCDS table name\n",
    "        date_col: Date column name\n",
    "        vintage: Date partition value (e.g., '2024-01-01') or 'whole'\n",
    "        partition_type: 'month', 'year', 'whole'\n",
    "        where_clause: Additional WHERE conditions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (row_count, query_time_seconds)\n",
    "    \"\"\"\n",
    "    # TODO: Implement actual Oracle query\n",
    "    # Example SQL template:\n",
    "    # SELECT COUNT(*) FROM {table_name}\n",
    "    # WHERE {date_col} = TO_DATE('{vintage}', 'YYYY-MM-DD')\n",
    "    # AND {where_clause}\n",
    "    \n",
    "    print(f\"  [PCDS] Querying {table_name} for {vintage}...\")\n",
    "    \n",
    "    # Placeholder - replace with actual query\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate query time\n",
    "    row_count = 1000  # Placeholder count\n",
    "    query_time = 0.1\n",
    "    \n",
    "    return row_count, query_time\n",
    "\n",
    "\n",
    "def get_aws_row_count(table_name, date_col, vintage, partition_type, where_clause=None):\n",
    "    \"\"\"\n",
    "    Query AWS Athena for row count\n",
    "    \n",
    "    Args:\n",
    "        table_name: AWS table name\n",
    "        date_col: Date column name\n",
    "        vintage: Date partition value or 'whole'\n",
    "        partition_type: 'month', 'year', 'whole'\n",
    "        where_clause: Additional WHERE conditions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (row_count, query_time_seconds)\n",
    "    \"\"\"\n",
    "    # TODO: Implement actual Athena query\n",
    "    # Example SQL template:\n",
    "    # SELECT COUNT(*) FROM {table_name}\n",
    "    # WHERE {date_col} = '{vintage}'\n",
    "    # AND {where_clause}\n",
    "    \n",
    "    print(f\"  [AWS]  Querying {table_name} for {vintage}...\")\n",
    "    \n",
    "    # Placeholder - replace with actual query\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate query time\n",
    "    row_count = 1000  # Placeholder count\n",
    "    query_time = 0.1\n",
    "    \n",
    "    return row_count, query_time\n",
    "\n",
    "\n",
    "def get_vintages(table_pair, partition_type):\n",
    "    \"\"\"\n",
    "    Determine which vintages/partitions to check\n",
    "    \n",
    "    Args:\n",
    "        table_pair: Dict with start_dt, end_dt, partition info\n",
    "        partition_type: 'month', 'year', 'whole'\n",
    "    \n",
    "    Returns:\n",
    "        list: List of vintage values to check\n",
    "    \"\"\"\n",
    "    if partition_type == 'whole':\n",
    "        return ['whole']\n",
    "    \n",
    "    # TODO: Generate date range based on start_dt, end_dt, and partition_type\n",
    "    # For now, return placeholder\n",
    "    return ['2024-01-01', '2024-02-01', '2024-03-01']  # Example monthly vintages\n",
    "\n",
    "\n",
    "print(\"Query functions defined (need implementation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Run Row Count Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "row_meta_results = []\n",
    "\n",
    "for idx, table_pair in enumerate(config['table_pairs'], 1):\n",
    "    print(f\"\\n[{idx}/{len(config['table_pairs'])}] Processing:\")\n",
    "    print(f\"  PCDS: {table_pair['pcds_tbl']}\")\n",
    "    print(f\"  AWS:  {table_pair['aws_tbl']}\")\n",
    "    \n",
    "    # Get vintages to check\n",
    "    partition_type = table_pair.get('partition', 'whole')\n",
    "    vintages = get_vintages(table_pair, partition_type)\n",
    "    \n",
    "    print(f\"  Vintages: {len(vintages)}\")\n",
    "    \n",
    "    for vintage in vintages:\n",
    "        # Query PCDS\n",
    "        pcds_count, pcds_time = get_pcds_row_count(\n",
    "            table_pair['pcds_tbl'],\n",
    "            table_pair.get('pcds_dt'),\n",
    "            vintage,\n",
    "            partition_type,\n",
    "            table_pair.get('pcds_where')\n",
    "        )\n",
    "        \n",
    "        # Query AWS\n",
    "        aws_count, aws_time = get_aws_row_count(\n",
    "            table_pair['aws_tbl'],\n",
    "            table_pair.get('aws_dt'),\n",
    "            vintage,\n",
    "            partition_type,\n",
    "            table_pair.get('aws_where')\n",
    "        )\n",
    "        \n",
    "        # Calculate match\n",
    "        match = pcds_count == aws_count\n",
    "        diff = aws_count - pcds_count\n",
    "        \n",
    "        # Store result\n",
    "        result = {\n",
    "            'table_index': idx - 1,\n",
    "            'pcds_tbl': table_pair['pcds_tbl'],\n",
    "            'aws_tbl': table_pair['aws_tbl'],\n",
    "            'vintage': vintage,\n",
    "            'pcds_count': pcds_count,\n",
    "            'aws_count': aws_count,\n",
    "            'match': match,\n",
    "            'diff': diff,\n",
    "            'pcds_query_time': pcds_time,\n",
    "            'aws_query_time': aws_time\n",
    "        }\n",
    "        row_meta_results.append(result)\n",
    "        \n",
    "        if not match:\n",
    "            print(f\"    ⚠ Mismatch at {vintage}: PCDS={pcds_count}, AWS={aws_count}, diff={diff}\")\n",
    "\n",
    "print(f\"\\n✓ Row meta check complete: {len(row_meta_results)} checks performed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "df_results = pd.DataFrame(row_meta_results)\n",
    "\n",
    "print(\"Row Meta Check Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total checks: {len(df_results)}\")\n",
    "print(f\"Matches: {df_results['match'].sum()}\")\n",
    "print(f\"Mismatches: {(~df_results['match']).sum()}\")\n",
    "print(f\"\\nTotal PCDS rows: {df_results['pcds_count'].sum():,}\")\n",
    "print(f\"Total AWS rows: {df_results['aws_count'].sum():,}\")\n",
    "print(f\"Total diff: {df_results['diff'].sum():,}\")\n",
    "\n",
    "# Show mismatches if any\n",
    "if (~df_results['match']).any():\n",
    "    print(\"\\nMismatches:\")\n",
    "    display(df_results[~df_results['match']][['pcds_tbl', 'aws_tbl', 'vintage', 'pcds_count', 'aws_count', 'diff']])\n",
    "else:\n",
    "    print(\"\\n✓ All row counts match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Update Configuration JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row_meta results to config\n",
    "config['row_meta'] = row_meta_results\n",
    "config['status']['step2_completed'] = True\n",
    "config['status']['step2_completed_at'] = datetime.now().isoformat()\n",
    "\n",
    "# Save updated config\n",
    "with open(CONFIG_JSON, 'w') as f:\n",
    "    json.dump(config, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Configuration updated and saved to: {CONFIG_JSON}\")\n",
    "print(f\"\\n✓ Step 2 Complete - Ready for Step 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
